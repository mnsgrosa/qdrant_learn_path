{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf1146b-5e8f-40d3-8aee-3d99e5d769c9",
   "metadata": {},
   "source": [
    "# Points, Vectors and payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de8303a-5f29-453a-9168-f697385a481d",
   "metadata": {},
   "source": [
    "## Points:\n",
    "\n",
    "At qdrant the point consists fo 3 elements: id, vector and payload <br>\n",
    "\n",
    "## Vector types in qdrant:\n",
    "\n",
    "### Dense vectors:\n",
    "\n",
    "Typical vectors generate by most of neural networks often called embeddings\n",
    "\n",
    "### Sparse vectors:\n",
    "\n",
    "Mathematically the same as dense vectors, but containing many zeros. Those are used for optimized <br>\n",
    "storage representation and have different shapes of vectors\n",
    "\n",
    "#### Representation of sparse vectors:\n",
    "\n",
    "the representation used follows the rule of list of (index, value) pairs: <br>\n",
    "index: integer position of non-zero values<br>\n",
    "value: floating point number<br>\n",
    "\n",
    "```\n",
    "[(6, 1.0), (7, 2.0)]\n",
    "```\n",
    "\n",
    "as Qdrant JSON format:\n",
    "\n",
    "```\n",
    "{\n",
    "\"indices\":[6,7],\n",
    "\"values\":[1.0,2.0]\n",
    "}\n",
    "```\n",
    "\n",
    "both indices and values must be the same size and indices must be unique and no need to sort <br>\n",
    "for qdrant as qdrant deals with it\n",
    "\n",
    "### Multivectors:\n",
    "\n",
    "Basically a tensor: a vector of vectors :)\n",
    "\n",
    "```\n",
    "\"vector\": [\n",
    "   [-0.013,  0.020, -0.007, -0.111],\n",
    "   [-0.030, -0.055,  0.001,  0.072],\n",
    "   [-0.041,  0.014, -0.032, -0.062],\n",
    "   # ...\n",
    "]\n",
    "```\n",
    "### Named Vectors:\n",
    "\n",
    "We can also place multiple vector types for a single qdrant point and we must specify while configurating\n",
    "\n",
    "```\n",
    "client.create_collection(\n",
    "    collection_name=\"{collection_name}\",\n",
    "    vectors_config={\n",
    "        \"image\": models.VectorParams(size=4, distance=models.Distance.DOT),\n",
    "        \"text\": models.VectorParams(size=5, distance=models.Distance.COSINE),\n",
    "    },\n",
    "    sparse_vectors_config={\"text-sparse\": models.SparseVectorParams()},\n",
    ")\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=\"{collection_name}\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=1,\n",
    "            vector={\n",
    "                \"image\": [0.9, 0.1, 0.1, 0.2],\n",
    "                \"text\": [0.4, 0.7, 0.1, 0.8, 0.1],\n",
    "                \"text-sparse\": {\n",
    "                    \"indices\": [1, 3, 5, 7],\n",
    "                    \"values\": [0.1, 0.2, 0.3, 0.4],\n",
    "                },\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "Here we can check that one point has two vectors associated, image(dense), text(dense) and text-sparse(sparsed)\n",
    "\n",
    "## Commonly used dimensions and models\n",
    "\n",
    "all-miniLm-l6-v2 -> 384 -> prototyping\n",
    "bge-base-en-v1.5 -> 768 -> baseline for rag\n",
    "openai-text-embedding-3-small -> 1536 -> commercial model for semantic search\n",
    "text-embedding-3-large -> 3072 -> maximun detail commecial model larg scale and high accuracy rag\n",
    "\n",
    "Notice that all those double the size 384 * 2 = 768 * 2 = 1536 * 2 = 3072\n",
    "\n",
    "## Comon embedding sources:\n",
    "\n",
    "### 1. FastEmbed by Qdrant (on-premise)\n",
    "\n",
    "- cpu friendly running on ONNX makin it 50% faster than pytorch based models\n",
    "- Uses by deffault bge-base-en-v1.5 for its size ~67MB\n",
    "\n",
    "Qdrant lets yus use any compatibnle model\n",
    "\n",
    "#### When should you use FastEmbed\n",
    "\n",
    "- On-premise execution for privacy\n",
    "- High speed cpu without pytorch\n",
    "- Scalable but low cost embedding generation solution\n",
    "\n",
    "### 2. Managed and integrated: Cloud providers\n",
    "\n",
    "- Qdrant cloud inference sending images or text in a single request\n",
    "- OpenAI and Anthropic cost based\n",
    "\n",
    "#### When should you use:\n",
    "\n",
    "- Ease of use and offload model management and infrastructure scaling\n",
    "- Need access to latest commecial models with minimal setup\n",
    "- can accept API costs and latency for high-quality embeddings\n",
    "\n",
    "### 3. On-premise, customizable: Open Source Models\n",
    "\n",
    "libraries sentence transformers from hugging face giving maximun flexibility and control\n",
    "\n",
    "#### When should you use:\n",
    "\n",
    "- Fine-tune needed\n",
    "- Full control over model architecture and deplyoment env\n",
    "- Has available GPU\n",
    "\n",
    "## Payloads (Metadata)\n",
    "\n",
    "Filter and refiner of querying vectors storing things as: date, price, descriptions, ratings and even complex structures\n",
    "\n",
    "## Payload types:\n",
    "\n",
    "- keyword: exact string matching\n",
    "- integer: 64-bit for numerical filtering\n",
    "- float: 64-bit for prices, ratings etc...\n",
    "- bool: true/false\n",
    "- geo: latitude/longitude pairs for location based queries\n",
    "- datetime: RFC-3339 firnat\n",
    "- UUID\n",
    "\n",
    "### Data structures:\n",
    "\n",
    "- arrays\n",
    "- json\n",
    "\n",
    "## Filtering logic:\n",
    "\n",
    "Complex queries can be created nesting filters using the following clauses:\n",
    "\n",
    "- must -> all conditions must be satisfied (AND logic)\n",
    "- should -> at least one (OR logic)\n",
    "- must_not -> None must be met (NOT logic)\n",
    "\n",
    "Example of query\n",
    "\n",
    "```\n",
    "models.Filter(\n",
    "    should=[\n",
    "        models.Filter(must=[\n",
    "            models.FieldCondition(key=\"category\", match=models.MatchValue(value=\"electronics\")),\n",
    "            models.FieldCondition(key=\"price\", range=models.Range(lt=200))\n",
    "        ]),\n",
    "        models.Filter(must=[\n",
    "            models.FieldCondition(key=\"category\", match=models.MatchValue(value=\"books\")),\n",
    "            models.FieldCondition(key=\"rating\", range=models.Range(gte=4.0))\n",
    "        ])\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "- match: exact value\n",
    "- range\n",
    "- geo: location based\n",
    "- full text: specific words or phrases whith a text field\n",
    "- Nested inside of arrays of objects\n",
    "\n",
    "### filtering capabilities reference:\n",
    "\n",
    "- match: exact\n",
    "- match any: or logic\n",
    "- match except: not in logic\n",
    "- range: numerical ranges -> \"range\":{\"gte\":50, \"lte\":200}\n",
    "- datetime range: date range -> \"range\":{\"gt\":2023-01-01T00:00:00Z\"}\n",
    "- full text: substring match -> \"match\":{\"text\":\"amazing services\"}\n",
    "- geospatial: location based -> \"geo_radius\": {\"center\":{...}. \"radius\":10000}\n",
    "- nested: array object -> \"nested\":{\"key\": \"reviews\", \"filter\": {...}}\n",
    "- has id: specific id -> \"has_id\":[1, 5, 10]\n",
    "- is empty: missing fields -> \"is_empty\":{\"key\":\"some_metadata_key\"}\n",
    "- is null: null values -> \"is_null\":{\"key\":\"some_metadata_key\"}\n",
    "- velues count: array length -> \"values_count\":{\"gt\":2}\n",
    "\n",
    "### Advanced filtering\n",
    "\n",
    "object:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"product\": \"Laptop\",\n",
    "  \"reviews\": [\n",
    "    {\"user\": \"alice\", \"rating\": 5, \"verified\": true},\n",
    "    {\"user\": \"bob\", \"rating\": 3, \"verified\": false}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "filter:\n",
    "\n",
    "```\n",
    "models.Filter(\n",
    "    must=[\n",
    "        models.NestedCondition(\n",
    "            nested=models.Nested(\n",
    "                key=\"reviews\",\n",
    "                filter=models.Filter(must=[\n",
    "                    models.FieldCondition(key=\"rating\", match=models.MatchValue(value=5)),\n",
    "                    models.FieldCondition(key=\"verified\", match=models.MatchValue(value=True))\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "### performance optimization\n",
    "\n",
    "To maximize filtering, create payload indexes for frequently filtered fields\n",
    "\n",
    "Examples:\n",
    "```\n",
    "# Index frequently filtered fields\n",
    "client.create_payload_index(\n",
    "    collection_name=\"{collection_name}\",\n",
    "    field_name=\"category\",\n",
    "    field_schema=models.PayloadSchemaType.KEYWORD,\n",
    ")\n",
    "\n",
    "# For multi-tenant applications, mark tenant fields\n",
    "client.create_payload_index(\n",
    "    collection_name=\"{collection_name}\",\n",
    "    field_name=\"tenant_id\",\n",
    "    field_schema=models.KeywordIndexParams(type=\"keyword\", is_tenant=True),\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "whenever there are too many filters qdrant may bypass vector indexing entirely and use payload indexes for faster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f849b47-884f-441a-9b81-298ea3fdbfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
