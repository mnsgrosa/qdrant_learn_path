{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded16df1-42d1-4120-92ad-515d6bbac5d4",
   "metadata": {},
   "source": [
    "# Combining vector search and filtering\n",
    "\n",
    "In real world is ideal to use filters. With this there are some challenges that qdrant solves\n",
    "\n",
    "## The callenge: filters break graph connectivity\n",
    "\n",
    "Let's check how range filters can show us this callenge:<br>\n",
    "Imagine we're searching for computer prices and we set to prices lower than 1000 and categorical filter for laptop. This may break paths in our graph since we may not have node connections sufficient for a traversal, not because of similarity but rather because of lack of paths connecting filtered out\n",
    "\n",
    "### Naive approaches and their problems:\n",
    "\n",
    "#### Post-filtering:\n",
    "\n",
    "Get top k most similar ones and filter out. This one has an issue, if the best match wasn't in that top k, you won't retrieve it, you will waste compute power and lose recall because of relevant points neve were retrieved\n",
    "\n",
    "#### Pre-filtering:\n",
    "\n",
    "Too restrictive filters fragment HNSW, breaking connectivity and traversal becomes inefficient or impossible\n",
    "\n",
    "## Qdrant solution: Filterable HNSW:\n",
    "\n",
    "Qdrant creates additional edges to maintain connectivty under filtering. There is a subgraph for each payload value, then merges it back to the original graph\n",
    "\n",
    "## Query planner: Adaptive strategy\n",
    "\n",
    "This happens on query time using a query planner it happens per segmend and is based on filter cardinality\n",
    "\n",
    "- Filter matches many points: HNSW skips nodes without match traversal avoiding pre filtering\n",
    "- Filter matches few points: If it matches a really smal proportion qdrant skips HNSW and fall for a full scan\n",
    "\n",
    "## Payload indexing:\n",
    "\n",
    "If it is planned to add indexes do as building the collection for is it known it is compute heavy to rebuild HNSW\n",
    "\n",
    "```python\n",
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "\n",
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))\n",
    "\n",
    "# For Colab:\n",
    "# from google.colab import userdata\n",
    "# client = QdrantClient(url=userdata.get(\"QDRANT_URL\"), api_key=userdata.get(\"QDRANT_API_KEY\"))\n",
    "\n",
    "collection_name = \"store\"\n",
    "vector_size = 768\n",
    "\n",
    "if client.collection_exists(collection_name=collection_name):\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=vector_size,\n",
    "        distance=models.Distance.COSINE,\n",
    "    ),\n",
    "    optimizers_config=models.OptimizersConfigDiff(\n",
    "        indexing_threshold=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Index frequently filtered fields\n",
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"category\",\n",
    "    field_schema=models.PayloadSchemaType.KEYWORD,\n",
    ")\n",
    "\n",
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"price\",\n",
    "    field_schema=models.PayloadSchemaType.FLOAT,\n",
    ")\n",
    "\n",
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"brand\",\n",
    "    field_schema=models.PayloadSchemaType.KEYWORD,\n",
    ")\n",
    "```\n",
    "\n",
    "Upload\n",
    "\n",
    "```python\n",
    "# Upload data\n",
    "import random\n",
    "\n",
    "points = []\n",
    "for i in range(1000):\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            vector=[random.random() for _ in range(vector_size)],\n",
    "            payload={\n",
    "                \"category\": random.choice([\"laptop\", \"phone\", \"tablet\"]),\n",
    "                \"price\": random.randint(0, 1000),\n",
    "                \"brand\": random.choice(\n",
    "                    [\"Apple\", \"Dell\", \"HP\", \"Lenovo\", \"Asus\", \"Acer\", \"Samsung\"]\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "client.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=points,\n",
    ")\n",
    "```\n",
    "\n",
    "## Memory considerations:\n",
    "\n",
    "Additional indexes add up memory consumpiton, so only index fields used in filtering conditions\n",
    "\n",
    "## Practical implementation:\n",
    "\n",
    "```python\n",
    "# Create filter combining multiple conditions\n",
    "filter_conditions = models.Filter(\n",
    "    must=[\n",
    "        models.FieldCondition(key=\"category\", match=models.MatchValue(value=\"laptop\")),\n",
    "        models.FieldCondition(key=\"price\", range=models.Range(lte=1000)),\n",
    "        models.FieldCondition(key=\"brand\", match=models.MatchAny(any=[\"Apple\", \"Dell\", \"HP\"])),\n",
    "    ]\n",
    ")\n",
    "\n",
    "query_vector = [random.random() for _ in range(vector_size)]\n",
    "\n",
    "# Execute filtered search\n",
    "results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    query_filter=filter_conditions,\n",
    "    limit=10,\n",
    "    search_params=models.SearchParams(hnsw_ef=128),\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "## Query planner decision matrix:\n",
    "\n",
    "- higher cardinality means hnsw with node skipping and should be usen to filter matches many points\n",
    "- very low means full scan over candidates and tiny result set\n",
    "\n",
    "## Performance optimiza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27463ae3-e68a-4030-8696-a875d8bbb3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
