{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2dd8d5-5f9e-48c6-9b10-3e15d43ea041",
   "metadata": {},
   "source": [
    "# Why indexing your vectors\n",
    "\n",
    "While using a vector database whenever itends to search for a similar vector we must search clustering them <br>\n",
    "so if a db has millions to billions entries using purely similarity will get really slow but in qdrant it is <br>\n",
    "used HNSW algorithm for faster querying.\n",
    "\n",
    "## HNSW\n",
    "\n",
    "HNSW lays out a structure that conects the vector points as graphs and let's us filter them as we desire for <br>\n",
    "a more efficient search time, if it's known that you want to query for a specific document why search all vectors? <br>\n",
    "\n",
    "## Configuring HNSW\n",
    "\n",
    "We can fine tune ou graph traversing with some hyperparameters for our indexing using m, ef_construct and hnsw_ef:\n",
    "\n",
    "### Graph connectivity: m\n",
    "\n",
    "This parameter controls the maximum number of connections per node in the graph\n",
    "\n",
    "- Higher m means denser graph with more neighbors improving search accuracy and increases memory usage and indexing time\n",
    "- lower m means sparser graph, less memory usage and sped up insertion but less accurate\n",
    "- typically goes by 8 to 64\n",
    "\n",
    "### Build toughness: ef_construct\n",
    "\n",
    "How many candidates are checked while inserting a vector\n",
    "\n",
    "- Higher values means more neighbors evaluated, resulting in a more comphensive and accurate graph, indexing slower an higher computing\n",
    "- lower values means sped up insertion but graph end up with less optimal connections, which can impact search accuracy\n",
    "- values 100 to 500 are commonly used higher values are better for complex data\n",
    "\n",
    "### Search thoroughness: hnsw_ef\n",
    "\n",
    "number of candidates evaluated during search query\n",
    "\n",
    "- Higher values translate to more accurate research but increases query time\n",
    "- Lower values less accuracy and speeds up\n",
    "- range 50 to 200+ depending on latency targer\n",
    "\n",
    "## Optimal settings:\n",
    "\n",
    "### High speed retrieval:\n",
    "\n",
    "Lower *m* and *hnsw_ef* and *ef_construct* high enough for acceptable recall\n",
    "\n",
    "### Maximum recall:\n",
    "\n",
    "Raise all parameters and accept slower queries and builds\n",
    "\n",
    "### Tight ram:\n",
    "\n",
    "Reduce *m* keep *ef_construct* construct high enough to avoid poor links\n",
    "\n",
    "## HNSW in action\n",
    "\n",
    "While brute force grows O(N) HNSW grows roughly O(log(n)) makin milion scale dataset searchable in seconds <br>\n",
    "it is filter aware through indexing allowing fast searches under structured conditions. This avoids costly full scans when filtering by<br>\n",
    "metadata. Latly it suports real time updates with high recall, fits semantic search and recommendation systems, scales from thousands <br>\n",
    "to bilions of vectors\n",
    "\n",
    "## Practical configuration:\n",
    "\n",
    "### Production:\n",
    "\n",
    "```python\n",
    "client.create_collection(\n",
    "    collection_name=\"production_vectors\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,\n",
    "        distance=models.Distance.COSINE,\n",
    "        hnsw_config=models.HnswConfigDiff(\n",
    "            m=16,  # Balanced connections (default)\n",
    "            ef_construct=200,  # Good build quality (default)\n",
    "            full_scan_threshold=10000,  # Use brute force below this size (default)\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "```\n",
    "\n",
    "### Development or testing: faster builds\n",
    "\n",
    "```python\n",
    "client.create_collection(\n",
    "    collection_name=\"dev_vectors\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=384,\n",
    "        distance=models.Distance.COSINE,\n",
    "        hnsw_config=models.HnswConfigDiff(\n",
    "            m=8,  # Fewer connections\n",
    "            ef_construct=100,  # Faster builds\n",
    "            full_scan_threshold=10000,  # Use brute force below this size (default)\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "```\n",
    "\n",
    "## Performance benchmarking:\n",
    "\n",
    "First we create and upload some toy data to a new collection\n",
    "\n",
    "```python\n",
    "import time\n",
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "\n",
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"), api_key=os.getenv(\"QDRANT_API_KEY\"))\n",
    "\n",
    "collection_name = \"my_collection\"\n",
    "\n",
    "if client.collection_exists(collection_name=collection_name):\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "\n",
    "# Development / testing: faster builds\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=4,\n",
    "        distance=models.Distance.COSINE,\n",
    "        hnsw_config=models.HnswConfigDiff(\n",
    "            m=8,  # Fewer connections\n",
    "            ef_construct=100,  # Faster builds\n",
    "            full_scan_threshold=100,  # Use brute force below this size (default)\n",
    "        ),\n",
    "    ),\n",
    "    optimizers_config=models.OptimizersConfigDiff(\n",
    "        indexing_threshold=100,  # Use brute force below this size (default)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# upload data\n",
    "import random\n",
    "\n",
    "points = []\n",
    "for i in range(20000):\n",
    "    points.append(\n",
    "        models.PointStruct(id=i, vector=[random.random() for _ in range(4)], payload={})\n",
    "    )\n",
    "client.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=points,\n",
    ")\n",
    "```\n",
    "\n",
    "### Search Performance:\n",
    "\n",
    "```python\n",
    "def benchmark_search_performance(collection_name, test_queries, ef_values):\n",
    "    \"\"\"Compare latency across hnsw_ef values\"\"\"\n",
    "\n",
    "    results = {}\n",
    "    for hnsw_ef in ef_values:\n",
    "        start_time = time.time()\n",
    "        for query in test_queries:\n",
    "            client.query_points(\n",
    "                collection_name=collection_name,\n",
    "                query=query,\n",
    "                limit=10,\n",
    "                search_params=models.SearchParams(hnsw_ef=hnsw_ef),\n",
    "            )\n",
    "\n",
    "        avg_time = (time.time() - start_time) / len(test_queries)\n",
    "        results[hnsw_ef] = avg_time\n",
    "        print(f\"hnsw_ef={hnsw_ef}: {avg_time:.3f}s per query\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test different hnsw_ef values\n",
    "test_queries = [\n",
    "    [30, 60, 90, 120],\n",
    "    [150, 180, 210, 240],\n",
    "    [270, 300, 330, 360],\n",
    "    [390, 420, 450, 480],\n",
    "    [510, 540, 570, 600],\n",
    "]\n",
    "\n",
    "ef_values = [32, 64, 128, 256]\n",
    "performance = benchmark_search_performance(collection_name, test_queries, ef_values)\n",
    "```\n",
    "\n",
    "### Inspecting performance and index use:\n",
    "\n",
    "The get_collection method returns current stats and configuration from collections like points_count, indexed_vectors_count or hnsw_config. It also lists payload_schema for payload indexes created\n",
    "\n",
    "#### If queries fell slow:\n",
    "\n",
    "- Check if filter fields have payload indexes\n",
    "- If the payload was set before building HNSW graph with setting m>0\n",
    "- If the payload was set before HNSW building graph (if m changes from 0 to higher number it builds automatically)\n",
    "- If *hnsw_config.full_scan_threshold* is too high\n",
    "\n",
    "Here how to inspect:\n",
    "\n",
    "```python\n",
    "# Inspect collection status\n",
    "info = client.get_collection(collection_name)\n",
    "\n",
    "vectors_per_point = 1  # set per your vectors_config\n",
    "vectors_count = info.points_count * vectors_per_point\n",
    "\n",
    "print(f\"Collection status: {info.status}\") \n",
    "print(f\"Total points: {info.points_count}\")\n",
    "print(f\"Indexed vectors: {info.indexed_vectors_count}\")\n",
    "\n",
    "if vectors_count:\n",
    "    proportion_unindexed = 1 - (info.indexed_vectors_count / vectors_count)\n",
    "else:\n",
    "    proportion_unindexed = 0\n",
    "\n",
    "print(f\"Proportion unindexed: {proportion_unindexed:.2%}\")\n",
    "\n",
    "if info.status == models.CollectionStatus.GREEN:\n",
    "    print(\"\\n✅ Collection is indexed and ready!\")\n",
    "elif info.status == models.CollectionStatus.YELLOW:\n",
    "    print(\"\\n⚠️ Collection is still being indexed (optimizing).\")\n",
    "else:\n",
    "    print(f\"\\n❌ Collection status is {info.status}.\")\n",
    "```\n",
    "\n",
    "## When not to use HNSW:\n",
    "\n",
    "### Small collections\n",
    "generally lesser than 10000 vectors, brute force in this case is faster and uses less RAM than building HNSW\n",
    "\n",
    "### Exact search requirements\n",
    "\n",
    "HNSW is apporixmate, if needed exact results, use brute force\n",
    "\n",
    "### Extreme memory constraints\n",
    "\n",
    "for very tight RAM budget:\n",
    "\n",
    "- Lower m: HNSW memory follows O(m * vector_count)\n",
    "- Vector scalar quantization: quantization often cuts RAM ~4x\n",
    "- Vector binary quantization: compresses to 1-bit per dimension and can cut RAM by large factors\n",
    "- On disk storage: set on_disk=True for vector and HNSW index to use mmap files only the most visited are cached in ram\n",
    "- Disable HNSW for reranking embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544d4f3-c604-46da-a8e2-ad5437b1fb6b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
